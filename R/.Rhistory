modelFit1
cbind.mids(X.imp.mice, y)
cbind.mids(X.imp.mice, rep(y, 5))
cbind.mids(X.imp.mice, rep(y, 25))
X.imp.mice
X.imp.mice[1:1000,]
summary(modelFit1)
pool(summary(modelFit1))
pool(modelFit1)
X.all
str(X.all)
str(X.all)
X.all[[1]]
str(X.all[[1]])
str(X.all[[2]])
str(y)
str(X.all)
str(X.train)
trainIdx
str(trainIdx)
trainIdx[[2]]
str(trainIdx)
trainIdx[[2]]
length(trainIdx[[2]])
str(trainIdx)
str(trainIdx)
1:10
str(X.test.cv)
preds
preds
which(preds > 0.5)
preds > 0.5
str(preds > 0.5)
table(preds > 0.5)
table(preds > 1.0)
table(preds > 0.3)
table(y)
182 / (869 + 182)
2500 / 10500
preds > 0.6
table(preds > 0.6)
preds > 0.6 - 1
(preds > 0.6) - 1
(preds > 0.6) - 0
as.integer(y.test.cv)
as.integer(y.test.cv) - 1
as.numeric(y.test.cv) - 1
as.numeric(y.test.cv)
for (i in 1:k) {
    ## Get target labels
    y.train.cv <- y[train.idx.all[[i]]]
    y.test.cv <- y[-train.idx.all[[i]]]
    ## For all imputations
    for (j in 1:m) {
        ## Get current imputation
        X.cur <- X.train[[j]]
        ## Split into train and test
        X.train.cv <- X.cur[train.idx.all[[i]], ]
        X.test.cv <- X.cur[-train.idx.all[[i]], ]
        ## Fit model and predict for test set
        mdl <- glm(y ~ ., data = X.train.cv, family='binomial')
        preds <- predict(mdl, X.test.cv, type = 'response')
        errs <- sum(abs((preds > 0.5) - (as.numeric(y.test.cv) - 1)))
        print(1 - (errs / length(y.test.cv)))
    }
}
formula(*.*)
formula(.*.)
str(X.train)
str(X.train[[1]])
for (i in 1:k) {
    ## Get target labels
    y.train.cv <- y[train.idx.all[[i]]]
    y.test.cv <- y[-train.idx.all[[i]]]
    preds <- list()
    ## For all imputations
    for (j in 1:m) {
        ## Get current imputation
        X.cur <- X.train[[j]]
        ## Split into train and test
        X.train.cv <- X.cur[train.idx.all[[i]], ]
        X.test.cv <- X.cur[-train.idx.all[[i]], ]
        ## Fit model and predict for test set
        mdl <- glm(y ~ ., data = X.train.cv, family='binomial')
        ## preds[[j]] <- predict(mdl, X.test.cv, type = 'response')
        preds <- predict(mdl, X.test.cv, type = 'response')
    }
    errs <- sum(abs((preds > 0.5) - (as.numeric(y.test.cv) - 1)))
    print(1 - (errs / length(y.test.cv)))
}
for (i in 1:k) {
    ## Get target labels
    y.train.cv <- y[train.idx.all[[i]]]
    y.test.cv <- y[-train.idx.all[[i]]]
    preds <- list()
    ## For all imputations
    for (j in 1:m) {
        ## Get current imputation
        X.cur <- X.train[[j]]
        ## Split into train and test
        X.train.cv <- X.cur[train.idx.all[[i]], ]
        X.test.cv <- X.cur[-train.idx.all[[i]], ]
        ## Fit model and predict for test set
        mdl <- with(X.train.cv, glm(y ~ . , data = X.train.cv, family='binomial'))
        ## preds[[j]] <- predict(mdl, X.test.cv, type = 'response')
        preds <- predict(mdl, X.test.cv, type = 'response')
    }
    errs <- sum(abs((preds > 0.5) - (as.numeric(y.test.cv) - 1)))
    print(1 - (errs / length(y.test.cv)))
}
for (i in 1:k) {
    ## Get target labels
    y.train.cv <- y[train.idx.all[[i]]]
    y.test.cv <- y[-train.idx.all[[i]]]
    preds <- list()
    ## For all imputations
    for (j in 1:m) {
        ## Get current imputation
        X.cur <- X.train[[j]]
        ## Split into train and test
        X.train.cv <- X.cur[train.idx.all[[i]], ]
        X.test.cv <- X.cur[-train.idx.all[[i]], ]
        ## Fit model and predict for test set
        mdl <- with(X.train.cv, glm(y ~ . + income:loss, data = X.train.cv, family='binomial'))
        ## preds[[j]] <- predict(mdl, X.test.cv, type = 'response')
        preds <- predict(mdl, X.test.cv, type = 'response')
    }
    errs <- sum(abs((preds > 0.5) - (as.numeric(y.test.cv) - 1)))
    print(1 - (errs / length(y.test.cv)))
}
str(X.train.cv)
for (i in 1:k) {
    ## Get target labels
    y.train.cv <- y[train.idx.all[[i]]]
    y.test.cv <- y[-train.idx.all[[i]]]
    preds <- list()
    ## For all imputations
    for (j in 1:m) {
        ## Get current imputation
        X.cur <- X.train[[j]]
        ## Split into train and test
        X.train.cv <- X.cur[train.idx.all[[i]], ]
        X.test.cv <- X.cur[-train.idx.all[[i]], ]
        ## Fit model and predict for test set
        mdl <- with(X.train.cv, glm(y ~ . + age:married, data = X.train.cv, family='binomial'))
        ## preds[[j]] <- predict(mdl, X.test.cv, type = 'response')
        preds <- predict(mdl, X.test.cv, type = 'response')
    }
    errs <- sum(abs((preds > 0.5) - (as.numeric(y.test.cv) - 1)))
    print(1 - (errs / length(y.test.cv)))
}
for (i in 1:k) {
    ## Get target labels
    y.train.cv <- y[train.idx.all[[i]]]
    y.test.cv <- y[-train.idx.all[[i]]]
    preds <- list()
    ## For all imputations
    for (j in 1:m) {
        ## Get current imputation
        X.cur <- X.train[[j]]
        ## Split into train and test
        X.train.cv <- X.cur[train.idx.all[[i]], ]
        X.test.cv <- X.cur[-train.idx.all[[i]], ]
        ## Fit model and predict for test set
        mdl <- with(X.train.cv, glm(y ~ . + age:married + sex:country, data = X.train.cv, family='binomial'))
        ## preds[[j]] <- predict(mdl, X.test.cv, type = 'response')
        preds <- predict(mdl, X.test.cv, type = 'response')
    }
    errs <- sum(abs((preds > 0.5) - (as.numeric(y.test.cv) - 1)))
    print(1 - (errs / length(y.test.cv)))
}
for (i in 1:k) {
    ## Get target labels
    y.train.cv <- y[train.idx.all[[i]]]
    y.test.cv <- y[-train.idx.all[[i]]]
    preds <- list()
    ## For all imputations
    for (j in 1:m) {
        ## Get current imputation
        X.cur <- X.train[[j]]
        ## Split into train and test
        X.train.cv <- X.cur[train.idx.all[[i]], ]
        X.test.cv <- X.cur[-train.idx.all[[i]], ]
        ## Fit model and predict for test set
        mdl <- with(X.train.cv, glm(y ~ . + age:married + sex:country + income:loss, data = X.train.cv, family='binomial'))
        ## preds[[j]] <- predict(mdl, X.test.cv, type = 'response')
        preds <- predict(mdl, X.test.cv, type = 'response')
    }
    errs <- sum(abs((preds > 0.5) - (as.numeric(y.test.cv) - 1)))
    print(1 - (errs / length(y.test.cv)))
}
for (i in 1:k) {
    ## Get target labels
    y.train.cv <- y[train.idx.all[[i]]]
    y.test.cv <- y[-train.idx.all[[i]]]
    preds <- list()
    ## For all imputations
    for (j in 1:m) {
        ## Get current imputation
        X.cur <- X.train[[j]]
        ## Split into train and test
        X.train.cv <- X.cur[train.idx.all[[i]], ]
        X.test.cv <- X.cur[-train.idx.all[[i]], ]
        ## Fit model and predict for test set
        mdl <- with(X.train.cv, glm(y ~ . + age:married + sex:country + income:loss + sex:yearsedu, data = X.train.cv, family='binomial'))
        ## preds[[j]] <- predict(mdl, X.test.cv, type = 'response')
        preds <- predict(mdl, X.test.cv, type = 'response')
    }
    errs <- sum(abs((preds > 0.5) - (as.numeric(y.test.cv) - 1)))
    print(1 - (errs / length(y.test.cv)))
}
preds
y.test.csv
y.test.cv
y.train.cv
train.idx.all
for (i in 1:k) {
    ## For all imputations
    for (j in 1:m) {
        ## Get current imputation
        X.cur1 <- X.train[[j]]
        ## Split into train and test
        X.train1.cv <- X.cur1[train.idx.all[[i]], ]
        X.test1.cv <- X.cur1[-train.idx.all[[i]], ]
        preds <- matrix(0, length(y.test.cv), m)
        ## For all train sets
        for (k in 1:m) {
            ## Get current imputation
            X.cur2 <- X.train[[k]]
            ## Split into train and test
            X.train2.cv <- X.cur2[train.idx.all[[i]], ]
            X.test2.cv <- X.cur2[-train.idx.all[[i]], ]
            ## Fit model and predict for test set
            mdl <- glm(y ~ ., data = X.train2.cv, family='binomial')
        ## preds[[j]] <- predict(mdl, X.test.cv, type = 'response')
            preds.cur <- predict(mdl, X.test1.cv, type = 'response')
            preds[,m] <- preds.cur
        }
        print(preds)
        ## TODO: move one step deeper
        errs <- sum(abs((preds > 0.5) - (as.numeric(X.test1.cv$y) - 1)))
        print(1 - (errs / length(X.test1.cv$y)))
}
}
X.test1.cv
for (i in 1:k) {
    ## For all imputations
    for (j in 1:m) {
        ## Get current imputation
        X.cur1 <- X.train[[j]]
        ## Split into train and test
        X.train1.cv <- X.cur1[train.idx.all[[i]], ]
        X.test1.cv <- X.cur1[-train.idx.all[[i]], ]
        preds <- matrix(0, nrow(X.test1.cv), m)
        ## For all train sets
        for (k in 1:m) {
            ## Get current imputation
            X.cur2 <- X.train[[k]]
            ## Split into train and test
            X.train2.cv <- X.cur2[train.idx.all[[i]], ]
            X.test2.cv <- X.cur2[-train.idx.all[[i]], ]
            ## Fit model and predict for test set
            ##mdl <- glm(y ~ ., data = X.train2.cv, family='binomial')
            mdl <- randomForest(y ~ ., data = X.train2.cv)
        ## preds[[j]] <- predict(mdl, X.test.cv, type = 'response')
            preds.cur <- predict(mdl, X.test1.cv, type = 'response')
            #print(preds.cur)
            preds[,k] <- preds.cur
            #print(preds)
            ## TODO: move one step deeper
        }
        preds.combined <- rowSums(preds) / m
        errs <- sum(abs((preds.combined > 0.5) - (as.numeric(X.test1.cv$y) - 1)))
        print(1 - (errs / length(X.test1.cv$y)))
    }
}
for (i in 1:k) {
    ## For all imputations
    for (j in 1:m) {
        ## Get current imputation
        X.cur1 <- X.train[[j]]
        ## Split into train and test
        X.train1.cv <- X.cur1[train.idx.all[[i]], ]
        X.test1.cv <- X.cur1[-train.idx.all[[i]], ]
        preds <- matrix(0, nrow(X.test1.cv), m)
        ## For all train sets
        for (k in 1:m) {
            ## Get current imputation
            X.cur2 <- X.train[[k]]
            ## Split into train and test
            X.train2.cv <- X.cur2[train.idx.all[[i]], ]
            X.test2.cv <- X.cur2[-train.idx.all[[i]], ]
            ## Fit model and predict for test set
            ##mdl <- glm(y ~ ., data = X.train2.cv, family='binomial')
            mdl <- randomForest(y ~ ., data = X.train2.cv)
        ## preds[[j]] <- predict(mdl, X.test.cv, type = 'response')
            ## for log
            ##preds.cur <- predict(mdl, X.test1.cv, type = 'response')
            preds.cur <- predict(mdl, X.test1.cv, type = 'prob')
            #print(preds.cur)
            preds[,k] <- preds.cur[, 1]
            #print(preds)
            ## TODO: move one step deeper
        }
        preds.combined <- rowSums(preds) / m
        errs <- sum(abs((preds.combined > 0.5) - (as.numeric(X.test1.cv$y) - 1)))
        print(1 - (errs / length(X.test1.cv$y)))
    }
}
preds.cur
preds.cur[, 1]
preds.cur[, "1"]
preds.cur$1
preds.cur$0
typeof(preds.cur)
preds.cur[1]
preds.cur[2\]
preds.cur[2]
data.frame(preds.cur)
levels(preds.cur)
attr(preds.cur)
attr(preds.cur, "prob")
attr(preds.cur, "prob")[, 1]
attr(preds.cur, "prob")[, 1]
pairs.panels(X.train)
head(svm.transduction)
head(svm.transduction$tr)
head(svm.transduction$ind)
svm.transduction$ind
svm.transduction$tr
head(X.train2.cv)
preds.cur
trans.y
for (i in 1:k) {
    ## For all imputations
    for (j in 1:m) {
        ## Get current imputation
        X.cur1 <- X.train[[j]]
        ## Split into train and test
        X.train1.cv <- X.cur1[train.idx.all[[i]], ]
        X.test1.cv <- X.cur1[-train.idx.all[[i]], ]
        actual <- X.test1.cv$y
        X.test1.cv$y <- NULL
        preds <- matrix(0, nrow(X.test1.cv), m)
        ## For all train sets
        for (k in 1:m) {
            ## Get current imputation
            X.cur2 <- X.train[[k]]
            ## Split into train and test
            X.train2.cv <- X.cur2[train.idx.all[[i]], ]
            X.test2.cv <- X.cur2[-train.idx.all[[i]], ]
            ##
            ## Add non-labeled feature vector
            ##
            ## Split labels from datasets
            train.y <- X.train2.cv$y
            train.y <- as.numeric(train.y)
            X.train2.cv$y <- NULL
            ##
            X.test2.cv$y <- NULL
            test.y <- rep(0, nrow(X.test[[1]]))
            ##
            X.trans.cv <- rbind(X.train2.cv, X.test[[1]])
            trans.y <- as.factor(c(train.y, test.y))
            ##
            ## Fit model and predict for test set
            ##mdl <- glm(y ~ ., data = X.train2.cv, family='binomial')
            ## Normal SVM:
            ##mdl <- svm(y ~ ., data = X.train2.cv, probability=TRUE)
            ## Tranductive:
            mdl <- SVM(x=X.trans.cv, y=trans.y,
                        transductive.learning=TRUE,
                       kernel="rbf")
            ##svm.transduction.pred <- predict(svm.transduction, test$x)
            ##mdl <- randomForest(y ~ ., data = X.train2.cv)
        ## preds[[j]] <- predict(mdl, X.test.cv, type = 'response')
            ## for log
            ##preds.cur <- predict(mdl, X.test1.cv, type = 'response')
            ##preds.cur <- predict(mdl, X.test1.cv, probability=TRUE)
            preds.cur <- predict(mdl, X.test1.cv, probability=TRUE)
            ##print(preds.cur)
            print(svm.accuracy(preds.cur, actual))
            ##preds[,k] <- attr(preds.cur, "prob")[, 2]
            #print(preds)
            ## TODO: move one step deeper
        }
        ##preds.combined <- rowSums(preds) / m
        ##errs <- sum(abs((preds.combined > 0.5) - (as.numeric(actual) - 1)))
        ##print(1 - (errs / length(X.test1.cv$y)))
    }
}
for (i in 1:k) {
    ## For all imputations
    for (j in 1:m) {
        ## Get current imputation
        X.cur1 <- X.train[[j]]
        ## Split into train and test
        X.train1.cv <- X.cur1[train.idx.all[[i]], ]
        X.test1.cv <- X.cur1[-train.idx.all[[i]], ]
        actual <- X.test1.cv$y
        X.test1.cv$y <- NULL
        preds <- matrix(0, nrow(X.test1.cv), m)
        ## For all train sets
        for (k in 1:m) {
            ## Get current imputation
            X.cur2 <- X.train[[k]]
            ## Split into train and test
            X.train2.cv <- X.cur2[train.idx.all[[i]], ]
            X.test2.cv <- X.cur2[-train.idx.all[[i]], ]
            ##
            ## Add non-labeled feature vector
            ##
            ## Split labels from datasets
            train.y <- X.train2.cv$y
            train.y <- as.numeric(train.y)
            X.train2.cv$y <- NULL
            ##
            X.test2.cv$y <- NULL
            test.y <- rep(0, nrow(X.test[[1]]))
            ##
            X.trans.cv <- rbind(X.train2.cv, X.test[[1]])
            trans.y <- as.factor(c(train.y, test.y))
            ##
            ## Fit model and predict for test set
            ##mdl <- glm(y ~ ., data = X.train2.cv, family='binomial')
            ## Normal SVM:
            ##mdl <- svm(y ~ ., data = X.train2.cv, probability=TRUE)
            ## Tranductive:
            mdl <- SVM(x=X.trans.cv, y=trans.y,
                        transductive.learning=TRUE,
                       kernel="rbf")
            ##svm.transduction.pred <- predict(svm.transduction, test$x)
            ##mdl <- randomForest(y ~ ., data = X.train2.cv)
        ## preds[[j]] <- predict(mdl, X.test.cv, type = 'response')
            ## for log
            ##preds.cur <- predict(mdl, X.test1.cv, type = 'response')
            ##preds.cur <- predict(mdl, X.test1.cv, probability=TRUE)
            preds.cur <- predict(mdl, X.test1.cv, probability=TRUE)
            ##print(preds.cur)
            print(svm.accuracy(preds.cur, actual))
            ##preds[,k] <- attr(preds.cur, "prob")[, 2]
            #print(preds)
            ## TODO: move one step deeper
        }
        ##preds.combined <- rowSums(preds) / m
        ##errs <- sum(abs((preds.combined > 0.5) - (as.numeric(actual) - 1)))
        ##print(1 - (errs / length(X.test1.cv$y)))
    }
}
X.train
head(X.train)
table(X.train$rich)
2500 / (10500)
table(sub1)
table(sub1$Prediction)
7259 / (38000)
7259 / (31083 + 7259)
X.train
describe(X.train)
summary(X.train)
2423 / 8000
1978 / 8000
summary(X.test)
2423 / 10500
1978 / 8000
2423 / 10500
1978 / 10500
2423 / 105002423 / 10500
len(X.test)
length(X.test)
nrow(X.test)
summary(X.test)
7200 / 38342
7600 / 38342
7370 / 38342
9000 / 38342
8870 / 38342
sum(is.na(X.train))/prod(dim(X.train))
sum(is.na(X.test))/prod(dim(X.test))
sum(is.na(X.train))/prod(dim(X.train))
sum(is.na(X.test))/prod(dim(X.test))
7686 / 38342
38342 / 10500
head(X.train)
LittleMCAR(X.train)
LittleMCAR(X.train)
little$p.value
little$df
str(little)
head(str(little))
little$df
little$chi.square
little.test$chi.square
little.test$p.value
little.test$df
complete.cases(X.test)
sum(complete.cases(X.test))
sum(complete.cases(X.train))
660 / 10500
2375 / 38342
